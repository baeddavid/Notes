** Chapter 1
*** 1.2 Structure
There are two components to a compiler.
1. Analysis
   Analysis applies a grammar structure to the input. It's goal is to generate an intermediate representation of the program and pass it to the synthesis part.

   It also make sure the code is syntactically sound and return any helpful messages if there are errors.

   The analysis part also collects information about the source program and stores information in a data structure called a symbol table, which is passed along with the intermediate representation to the synthesis part.

   The analysis part of the compiler is referred to as the front end of the compiler. Easy to think of it as front end since we feed the source program into the analysis first.
2. Synthesis
   Synthesis constructs the desired target program from the intermediate representation and the information from the symbol table.

   In contrast to analysis, synthesis is referred to as the back end of the compiler.

Source Program --> ANALYSIS --> ([Symbol Table], [Intermediate Representation]) --> BACKEND --> Target Program
**** Analysis
Analysis can be broken up further into seperate parts.
The first part is called the Lexical Analysis
***** Lexical Analysis
The first phase of a compiler is called lexical analysis or scanning.

The lexical analyzer reads the the stream of characters making up the source program and groups them into meaningful sequences called Lexemes.
****** Lexeme
For each lexeme, the lexical analyzer produces as output a token of the form:
    <token-name, attribute value>
In the token (token-name) is an abstract symbol that is used during syntax. The second component, (attribute value) points to an entry in the symbol table for this token.
****** Example
Let us assume that we are given the input
position = inital + rate * 60
We can group the following characters in this assignment into the following lexemes.
1. Position
   position is a lexeme that would be mapped into a token <id, 1>, where id is an abstract symbol standing for identifier and 1 points to the symbol table entry for position.
2. =
   The assignment symbol = is a lexeme that is mapped to the token <=>. Since this token needs no attribute-value, we have omitted the second component.
3. initial
   initial is a lexeme that would be mapped into a token <id, 2>, where 2 points to the symbol table entry for initial.
4. + is a lexeme that is that is mapped to the token <+>.
5. Rate
   rate is a lexeme that is mapped to the token <id, 3> where 3 points to the symbol table entry for rate.
6. *
   * is a lexeme that is mapped to the token <*>.
7. 60
   60 is a lexeme that is mapped to the token <60>.
   Technically 60 would be mapped to <number, 60> but it is written as <60> for simplicty sake.
***** Semantic Analysis
The semantic analyzer is the second part. It uses the syntax tree and the information in the symbol table to check the source program for semantic consistency with the language definition.

It gathers type information and saves it in either the syntax tree or the symbol table.
****** Type Checking
Type checking is an important part of semantic analysis. The compiler checks each operator for matching operands.

Language specification may permit typer conversions called coercions.
***** Intermediate Code Generation
When a compiler translates a source program into target code, a compiler may construct one or more intermediate representations, which can have a variety of forms.

After syntax and semantic analysis, many compilers generate an explicit low level or machine-like intermediate representation. The intermediate representation should have two important properties:

1. It should be easy to produce
2. It should be easy to translate

****** Three-address code
Three-address code consists of a sequence of assembly-like instructions with three operands per instruction. Each operand can act like a register.

t1 = inttofloat(60)
t2 = id3 * t1
t3 = id2 + t2
id1 = t3

***** Code Optimization
In this stage of compiling, it attempts to improve the intermediate code so that better target code will result. Usually better means faster, but other objectives may be desired, such as shorter code, or target code that consumes less power.

A simple intermediate code generation algorithm followed by code optimization is a reasonable way to generate good target code.

**** Code Generation
The code generator takes as input an intermediate representation of the source program and maps it into the target language. If the target language is machine code, registers or memory locations are selected for each of the variables used by the program. Then, the intermediate instructions are translated into sequences of machine instructions that perform the same task. A crucial aspect of code generation is the judicious assignment of registers to hold variables.

LDF R2, id3
MULF R2, R2, #60.0
LDF R1, id2
ADDF R1, R1, R2
STF id1, R1

**** Symbol Table Management
An essential function of a compiler is to record the variable names used in the source program and collect information about various attributes of each name.

The symbol table is a data structure containing a record for each variable name, with fields for the attributes of the name.

*** Kinds of Languages
**** Generations
***** First Generation
First generation languages are the machine languages.
***** Second Generation
Second generation langauges are the assembly languages.
***** Third Generation
Third generation, also known as higher-level languages, like Fortran, Cobol, List, C, C++, C#, Java
***** Fourth Generation
Fourth generation languges are languages developed for specific purposes. NOMAD, SQL, Postscript.
***** Fifth Generation
Fifth generation langauges are logic and constraint based languages like Prolog and OPS5.
**** Types
***** Imperative
Languages where a program specifies how a computation is to be done.
***** Declartive
Languages in which a program specifies what computation is to be done.
*** Optimization for Computer Architecture
There are two basic technicques we can use to optimize compilers.
**** Parallelism
Parallelism can be found at several levels. The instruction level and at the processor level.
***** Instruction Level
Multiple operations are executed simultaneously
***** Processor Level
Different threads of the same application are run on different processors.
**** Memory Hierarchies
A memory hierarchy consists of several levels of storage with different speeds and sizes, with the level closest to the processor being the fastest but smallest.
*** Programming Languages Fundamentals
**** Static/Dynamic Distinction
If a language uses a policy that allows the compiler to decide an issue we say that language uses a static policy or that the issue can be decided at compile time.

If a policy only allows a decision to be made when we execute the program it is said to be a dynamic policy or to require a decision at run time.
